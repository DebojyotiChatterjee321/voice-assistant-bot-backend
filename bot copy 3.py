#
# Copyright (c) 2024–2025, Daily
#
# SPDX-License-Identifier: BSD 2-Clause License
#

"""voice_assistant_bot - Pipecat Voice Agent

This bot uses a cascade pipeline: Speech-to-Text → LLM → Text-to-Speech

Generated by Pipecat CLI

Required AI services:
- Elevenlabs (Speech-to-Text)
- Google_Gemini (LLM)
- Elevenlabs (Text-to-Speech)

Run the bot using::

    uv run bot.py
"""


import os
from pathlib import Path

from aiohttp import ClientSession
from dotenv import load_dotenv
from loguru import logger
from threading import Thread
from aiohttp import web
import aiohttp_cors
from multiprocessing import Process

from pipecat.audio.turn.smart_turn.local_smart_turn_v3 import LocalSmartTurnAnalyzerV3
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.frames.frames import LLMRunFrame
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.adapters.schemas.tools_schema import ToolsSchema
from pipecat.processors.aggregators.llm_context import LLMContext
from pipecat.processors.aggregators.llm_response_universal import LLMContextAggregatorPair
from pipecat.processors.frameworks.rtvi import RTVIObserver, RTVIProcessor
from pipecat.runner.types import RunnerArguments, SmallWebRTCRunnerArguments
from pipecat.services.elevenlabs.stt import ElevenLabsSTTService
from pipecat.services.elevenlabs.tts import ElevenLabsTTSService
from pipecat.services.google.llm import GoogleLLMService
from pipecat.transports.base_transport import BaseTransport, TransportParams
from pipecat.transports.smallwebrtc.connection import SmallWebRTCConnection
from pipecat.transports.smallwebrtc.transport import SmallWebRTCTransport

from db_tools import DatabaseTools

load_dotenv(override=True)




async def run_bot(transport: BaseTransport):
    """Main bot logic."""
    logger.info("Starting bot")

    async with ClientSession() as session:
        # Speech-to-Text service
        stt = ElevenLabsSTTService(
            api_key=os.getenv("ELEVENLABS_API_KEY"),
            aiohttp_session=session
        )


        # Text-to-Speech service
        tts = ElevenLabsTTSService(
            api_key=os.getenv("ELEVENLABS_API_KEY"),
            voice_id=os.getenv("ELEVENLABS_VOICE_ID")
        )


        # LLM service
        llm = GoogleLLMService(
            api_key=os.getenv("GOOGLE_API_KEY"),
            model=os.getenv("GOOGLE_MODEL")
        )


        messages = [
            {
                "role": "system",
                "content": (
                    "You are a helpful e-commerce voice assistant for a retail store. "
                    "Your first message to the customer should be only - Hello, how can I assist you today?"
                    "You reply in crisp and concise, but clear and informative."
                    "Assist customers with product discovery, availability, pricing, order status, returns, and account-related questions."
                    "Ask for necessary order identifiers before sharing sensitive information. "
                    "If a request is unrelated to shopping or orders, politely decline and steer the customer back to supported topics."
                ),
            },
        ]

        context = LLMContext(messages)
        context_aggregator = LLMContextAggregatorPair(context)

        data_dir = Path(__file__).parent / "data"
        db_path_env = os.getenv("ORDERS_DB_PATH")
        db_path = Path(db_path_env) if db_path_env else Path(__file__).parent / "orders.db"

        db_tools = DatabaseTools(db_path=db_path, data_dir=data_dir)
        tool_functions = list(db_tools.tool_functions)
        for tool in tool_functions:
            llm.register_direct_function(tool)

        context.set_tools(ToolsSchema(standard_tools=tool_functions))
        context.set_tool_choice({"type": "auto"})

        rtvi = RTVIProcessor()

        # Pipeline - assembled from reusable components
        pipeline = Pipeline([
            transport.input(),

            rtvi,

            stt,


            context_aggregator.user(),

            llm,

            tts,

            transport.output(),



            context_aggregator.assistant(),

        ])


        task = PipelineTask(
            pipeline,
            params=PipelineParams(
                enable_metrics=True,
                enable_usage_metrics=True,
            ),
            observers=[
                RTVIObserver(rtvi),
            ],
        )

        @transport.event_handler("on_client_connected")
        async def on_client_connected(transport, client):
            logger.info("Client connected")
            # Kick off the conversation
            messages.append({"role": "system", "content": "Say hello and briefly introduce yourself."})
            await task.queue_frames([LLMRunFrame()])

        @transport.event_handler("on_client_disconnected")
        async def on_client_disconnected(transport, client):
            logger.info("Client disconnected")
            await task.cancel()




        runner = PipelineRunner(handle_sigint=False)

        await runner.run(task)


async def bot(runner_args: RunnerArguments):
    """Main bot entry point."""

    transport = None

    match runner_args:
        case SmallWebRTCRunnerArguments():
            webrtc_connection: SmallWebRTCConnection = runner_args.webrtc_connection

            transport = SmallWebRTCTransport(
                webrtc_connection=webrtc_connection,
                params=TransportParams(
                    audio_in_enabled=True,
                    audio_out_enabled=True,
                    vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2)),
                    turn_analyzer=LocalSmartTurnAnalyzerV3(),
                ),
            )
        case _:
            logger.error(f"Unsupported runner arguments type: {type(runner_args)}")
            return

    await run_bot(transport)

def run_health_server(port):
    """Separate process for health checks"""
    allowed_origins_env = os.getenv("CORS_ALLOW_ORIGINS", "*")
    allowed_origins = [origin.strip() for origin in allowed_origins_env.split(",") if origin.strip()]
    allow_methods = os.getenv("CORS_ALLOW_METHODS", "GET,POST,OPTIONS")
    allow_headers = os.getenv("CORS_ALLOW_HEADERS", "Authorization,Content-Type")
    allow_credentials = os.getenv("CORS_ALLOW_CREDENTIALS", "false").lower() == "true"
    max_age = os.getenv("CORS_MAX_AGE", "600")

    @web.middleware
    async def cors_middleware(request, handler):
        if request.method == "OPTIONS":
            response = web.Response(status=204)
        else:
            response = await handler(request)

        origin = request.headers.get("Origin")
        allow_origin = None
        if "*" in allowed_origins:
            allow_origin = "*"
        elif origin and origin in allowed_origins:
            allow_origin = origin

        if allow_origin:
            response.headers["Access-Control-Allow-Origin"] = allow_origin
            if allow_origin != "*":
                response.headers["Vary"] = "Origin"

        response.headers["Access-Control-Allow-Methods"] = allow_methods
        response.headers["Access-Control-Allow-Headers"] = allow_headers
        response.headers["Access-Control-Max-Age"] = max_age

        if allow_credentials and allow_origin and allow_origin != "*":
            response.headers["Access-Control-Allow-Credentials"] = "true"

        return response

    async def health(request):
        return web.Response(text='{"status":"healthy"}')

    app = web.Application()

    # Configure CORS
    cors = aiohttp_cors.setup(app, defaults={
        "*": aiohttp_cors.ResourceOptions(
            allow_credentials=True,
            expose_headers="*",
            allow_headers="*",
            allow_methods="*"
        )
    })

    async def health(request):
        return web.Response(text='OK')

    route = app.router.add_get('/health', health)
    cors.add(route)  # Add CORS to route

if __name__ == "__main__":
    # Start health server in separate process
    port = int(os.getenv("PORT", 8080))
    health_process = Process(target=run_health_server, args=(port,))
    health_process.start()
    
    print("Health server started, now starting Pipecat...")
    
    # Run Pipecat
    from pipecat.runner.run import main
    main()