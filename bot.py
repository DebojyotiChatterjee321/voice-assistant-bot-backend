#
# Copyright (c) 2024–2025, Daily
#
# SPDX-License-Identifier: BSD 2-Clause License
#

"""voice_assistant_bot - Pipecat Voice Agent

This bot uses a cascade pipeline: Speech-to-Text → LLM → Text-to-Speech

Generated by Pipecat CLI

Required AI services:
- Elevenlabs (Speech-to-Text)
- Google_Gemini (LLM)
- Elevenlabs (Text-to-Speech)

Run the bot using::

    python bot.py
"""

import asyncio
import os
import re
import sys
import time
from dataclasses import dataclass
from enum import Enum, auto
from typing import Dict, Optional

from aiohttp import ClientSession
from dotenv import load_dotenv
from loguru import logger

from pipecat.audio.turn.smart_turn.local_smart_turn_v3 import LocalSmartTurnAnalyzerV3
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.frames.frames import (
    CancelFrame,
    EndFrame,
    LLMFullResponseEndFrame,
    LLMFullResponseStartFrame,
    LLMTextFrame,
    StartFrame,
    TranscriptionFrame,
)
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.processors.frame_processor import FrameDirection, FrameProcessor
from pipecat.processors.frameworks.rtvi import RTVIObserver, RTVIProcessor
from pipecat.runner.types import RunnerArguments, SmallWebRTCRunnerArguments
from pipecat.services.elevenlabs.stt import ElevenLabsSTTService
from pipecat.services.elevenlabs.tts import ElevenLabsTTSService
from pipecat.transports.base_transport import BaseTransport, TransportParams
from pipecat.transports.smallwebrtc.connection import SmallWebRTCConnection
from pipecat.transports.smallwebrtc.transport import SmallWebRTCTransport

class CustomElevenLabsSTTService(ElevenLabsSTTService):
    async def run_stt(self, frame):
        start = time.perf_counter()
        async for result in super().run_stt(frame):
            processing_time = time.perf_counter() - start
            result.metadata["processing_time"] = processing_time
            yield result

load_dotenv(override=True)

@dataclass
class TurnTiming:
    stt_ms: float = 0.0
    dialogue_ms: float = 0.0
    tts_ms: float = 0.0


class TimingObserver(FrameProcessor):
    """Collect per-turn timing for STT, scripted dialogue, and TTS."""

    def __init__(self) -> None:
        super().__init__(name="TimingObserver", enable_direct_mode=True)
        self._stt_start: Optional[float] = None
        self._dialogue_start: Optional[float] = None
        self._tts_start: Optional[float] = None
        self._turn_id = 0
        self._timings: Dict[int, TurnTiming] = {}
        self._current_text = ""

    def _current(self) -> TurnTiming:
        timing = self._timings.setdefault(self._turn_id, TurnTiming())
        return timing

    async def process_frame(self, frame, direction: FrameDirection):
        await super().process_frame(frame, direction)

        if isinstance(frame, StartFrame):
            await self.push_frame(frame, direction)
            return

        if isinstance(frame, TranscriptionFrame) and direction == FrameDirection.DOWNSTREAM:
            self._turn_id += 1
            processing_time = frame.metadata.get("processing_time")
            if processing_time:
                self._current().stt_ms = processing_time * 1000
            self._dialogue_start = time.perf_counter()
            self._current()
        elif isinstance(frame, LLMFullResponseStartFrame):
            if self._dialogue_start:
                self._current().dialogue_ms = (time.perf_counter() - self._dialogue_start) * 1000
            self._dialogue_start = None
            self._tts_start = time.perf_counter()
        elif isinstance(frame, LLMFullResponseEndFrame):
            if self._tts_start:
                self._current().tts_ms += (time.perf_counter() - self._tts_start) * 1000
            self._tts_start = None
            timing = self._timings.get(self._turn_id)
            if timing:
                total_ms = timing.stt_ms + timing.dialogue_ms + timing.tts_ms
                logger.info(
                    f"Turn {self._turn_id}: '{self._current_text}' — STT: {timing.stt_ms:.1f} ms | Dialogue: {timing.dialogue_ms:.1f} ms | TTS: {timing.tts_ms:.1f} ms | Total: {total_ms:.1f} ms"
                )
        elif isinstance(frame, LLMTextFrame):
            self._current_text = frame.text or ""

        await self.push_frame(frame, direction)


class DialogueState(Enum):
    """State machine for the scripted conversation."""

    INIT = auto()
    AWAITING_NAME = auto()
    AWAITING_ORDER_REQUEST = auto()
    AWAITING_ORDER_ID = auto()
    AWAITING_THANK_YOU = auto()
    COMPLETE = auto()


def _normalize(text: str) -> str:
    """Lowercase and strip punctuation for robust matching."""

    return re.sub(r"[^a-z0-9 ]", "", text.lower()).strip()


class ScriptedDialogueProcessor(FrameProcessor):
    """Frame processor that enforces a deterministic conversation."""

    GREETING = "Hello, please tell me your name."
    ASSIST_PROMPT_TEMPLATE = "Hi there {username}, how can I assist you today?"
    ORDER_ID_PROMPT = "Please provide me your order id."
    ORDER_RESPONSE = "Your order is shipped yesterday and will be delivered tomorrow"
    ORDER_REQUEST_EXPECTED = _normalize("I need details on my order")
    THANK_YOU_EXPECTED = _normalize("Thank you")

    def __init__(self) -> None:
        super().__init__(name="ScriptedDialogueProcessor", enable_direct_mode=True)
        self._state = DialogueState.INIT
        self._ready_event: asyncio.Event = asyncio.Event()
        self._user_name: str | None = None
        self._order_id: str | None = None

    async def begin_dialogue(self) -> None:
        """Emit the scripted greeting once the pipeline is ready."""

        await self._ready_event.wait()
        if self._state != DialogueState.INIT:
            logger.debug("Scripted dialogue already started; skipping greeting.")
            return

        logger.info("Scripted dialogue: sending greeting")
        await self._emit_assistant(self.GREETING)
        self._state = DialogueState.AWAITING_NAME

    async def process_frame(self, frame, direction: FrameDirection):
        await super().process_frame(frame, direction)

        if isinstance(frame, StartFrame):
            await self.push_frame(frame, direction)
            self._ready_event.set()
            return

        if isinstance(frame, (EndFrame, CancelFrame)):
            await self.push_frame(frame, direction)
            self._ready_event.clear()
            return

        if isinstance(frame, TranscriptionFrame):
            await self._handle_transcription(frame)
            await self.push_frame(frame, direction)
            return

        await self.push_frame(frame, direction)

    async def _handle_transcription(self, frame: TranscriptionFrame) -> None:
        text = (frame.text or "").strip()
        if not text:
            return

        normalized = _normalize(text)
        logger.debug(f"Scripted dialogue received transcription: '{text}'")

        if self._state == DialogueState.AWAITING_NAME:
            if text:
                self._user_name = text
                logger.info("Scripted dialogue: captured user name '%s'", text)
                await self._emit_assistant(
                    self.ASSIST_PROMPT_TEMPLATE.format(username=text)
                )
                self._state = DialogueState.AWAITING_ORDER_REQUEST
            else:
                logger.warning(
                    "Received empty response while awaiting user name"
                )
                await self._emit_assistant("I didn't catch your name. Could you please repeat it?")
        elif self._state == DialogueState.AWAITING_ORDER_REQUEST:
            if normalized == self.ORDER_REQUEST_EXPECTED:
                logger.info("Scripted dialogue: received expected order request")
                await self._emit_assistant(self.ORDER_ID_PROMPT)
                self._state = DialogueState.AWAITING_ORDER_ID
            else:
                logger.warning(
                    "Unexpected user utterance while awaiting order request: '%s'",
                    text,
                )
                await self._emit_assistant(
                    "Please say 'I need details on my order.'"
                )
        elif self._state == DialogueState.AWAITING_ORDER_ID:
            if text:
                self._order_id = text
                logger.info("Scripted dialogue: captured order id '%s'", text)
                await self._emit_assistant(self.ORDER_RESPONSE)
                self._state = DialogueState.AWAITING_THANK_YOU
            else:
                logger.warning(
                    "Received empty response while awaiting order id"
                )
                await self._emit_assistant("Please provide me your order id.")
        elif self._state == DialogueState.AWAITING_THANK_YOU:
            if normalized == self.THANK_YOU_EXPECTED:
                logger.info("Scripted dialogue: conversation complete, awaiting disconnect")
                self._state = DialogueState.COMPLETE
            else:
                logger.warning(
                    "Unexpected user utterance while awaiting thank you: '%s'",
                    text,
                )
                await self._emit_assistant(
                    "Please respond with 'Thank you' to end the session."
                )
        else:
            logger.debug("Scripted dialogue ignoring transcription in state %s", self._state)

    async def _emit_assistant(self, text: str) -> None:
        await self.push_frame(LLMFullResponseStartFrame(), FrameDirection.DOWNSTREAM)
        await self.push_frame(LLMTextFrame(text=text), FrameDirection.DOWNSTREAM)
        await self.push_frame(LLMFullResponseEndFrame(), FrameDirection.DOWNSTREAM)


async def run_bot(transport: BaseTransport):
    """Main bot logic."""
    logger.info("Starting bot")

    async with ClientSession() as session:
        # Speech-to-Text service
        stt = CustomElevenLabsSTTService(
            api_key=os.getenv("ELEVENLABS_API_KEY"),
            aiohttp_session=session
        )

        # Text-to-Speech service
        tts = ElevenLabsTTSService(
            api_key=os.getenv("ELEVENLABS_API_KEY"),
            voice_id=os.getenv("ELEVENLABS_VOICE_ID")
        )

        rtvi = RTVIProcessor()
        dialogue = ScriptedDialogueProcessor()
        timing_observer = TimingObserver()

        # Pipeline - assembled from reusable components
        pipeline = Pipeline([
            transport.input(),
            rtvi,
            stt,
            dialogue,
            tts,
            transport.output(),
            timing_observer,
        ])

        task = PipelineTask(
            pipeline,
            params=PipelineParams(
                enable_metrics=True,
                enable_usage_metrics=True,
            ),
            observers=[
                RTVIObserver(rtvi),
            ],
        )

        @transport.event_handler("on_client_connected")
        async def on_client_connected(transport, client):
            logger.info("Client connected")
            await dialogue.begin_dialogue()

        @transport.event_handler("on_client_disconnected")
        async def on_client_disconnected(transport, client):
            logger.info("Client disconnected")
            await task.cancel()

        runner = PipelineRunner(handle_sigint=False)
        await runner.run(task)


async def bot(runner_args: RunnerArguments):
    """Main bot entry point."""

    transport = None

    match runner_args:
        case SmallWebRTCRunnerArguments():
            webrtc_connection: SmallWebRTCConnection = runner_args.webrtc_connection

            transport = SmallWebRTCTransport(
                webrtc_connection=webrtc_connection,
                params=TransportParams(
                    audio_in_enabled=True,
                    audio_out_enabled=True,
                    vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2)),
                    turn_analyzer=LocalSmartTurnAnalyzerV3(),
                ),
            )
        case _:
            logger.error(f"Unsupported runner arguments type: {type(runner_args)}")
            return

    await run_bot(transport)


if __name__ == "__main__":
    # Render deployment configuration
    # Render sets PORT env var (default 10000) and requires binding to 0.0.0.0
    port = int(os.getenv("PORT", 10000))
    host = os.getenv("HOST", "0.0.0.0")
    
    logger.info(f"Configuring for Render deployment: host={host}, port={port}")
    
    # Configure command line arguments for Pipecat runner
    # Remove any existing port/host arguments to avoid conflicts
    args_to_remove = []
    for i, arg in enumerate(sys.argv):
        if arg in ["--port", "-p", "--host", "-h"]:
            args_to_remove.extend([i, i + 1])
        elif arg.startswith("--port=") or arg.startswith("--host="):
            args_to_remove.append(i)
    
    # Remove in reverse order to maintain indices
    for i in sorted(args_to_remove, reverse=True):
        if i < len(sys.argv):
            sys.argv.pop(i)
    
    # Add Render-specific configuration
    sys.argv.extend(["--host", host, "--port", str(port)])
    
    logger.info(f"Starting Pipecat with args: {sys.argv[1:]}")
    
    # Run Pipecat
    from pipecat.runner.run import main
    main()