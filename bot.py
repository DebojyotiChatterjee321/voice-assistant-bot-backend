#
# Copyright (c) 2024–2025, Daily
#
# SPDX-License-Identifier: BSD 2-Clause License
#

"""voice_assistant_bot - Pipecat Voice Agent

This bot uses a cascade pipeline: Speech-to-Text → LLM → Text-to-Speech

Generated by Pipecat CLI

Required AI services:
- Elevenlabs (Speech-to-Text)
- Google_Gemini (LLM)
- Elevenlabs (Text-to-Speech)

Run the bot using::

    uv run bot.py
"""


import os
from pathlib import Path

from aiohttp import ClientSession
from dotenv import load_dotenv
from loguru import logger
from threading import Thread
from aiohttp import web

from pipecat.audio.turn.smart_turn.local_smart_turn_v3 import LocalSmartTurnAnalyzerV3
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.frames.frames import LLMRunFrame
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.adapters.schemas.tools_schema import ToolsSchema
from pipecat.processors.aggregators.llm_context import LLMContext
from pipecat.processors.aggregators.llm_response_universal import LLMContextAggregatorPair
from pipecat.processors.frameworks.rtvi import RTVIObserver, RTVIProcessor
from pipecat.runner.types import RunnerArguments, SmallWebRTCRunnerArguments
from pipecat.services.elevenlabs.stt import ElevenLabsSTTService
from pipecat.services.elevenlabs.tts import ElevenLabsTTSService
from pipecat.services.google.llm import GoogleLLMService
from pipecat.transports.base_transport import BaseTransport, TransportParams
from pipecat.transports.smallwebrtc.connection import SmallWebRTCConnection
from pipecat.transports.smallwebrtc.transport import SmallWebRTCTransport

from db_tools import DatabaseTools

load_dotenv(override=True)




async def run_bot(transport: BaseTransport):
    """Main bot logic."""
    logger.info("Starting bot")

    async with ClientSession() as session:
        # Speech-to-Text service
        stt = ElevenLabsSTTService(
            api_key=os.getenv("ELEVENLABS_API_KEY"),
            aiohttp_session=session
        )


        # Text-to-Speech service
        tts = ElevenLabsTTSService(
            api_key=os.getenv("ELEVENLABS_API_KEY"),
            voice_id=os.getenv("ELEVENLABS_VOICE_ID")
        )


        # LLM service
        llm = GoogleLLMService(
            api_key=os.getenv("GOOGLE_API_KEY"),
            model=os.getenv("GOOGLE_MODEL")
        )


        messages = [
            {
                "role": "system",
                "content": (
                    "You are a helpful e-commerce voice assistant for a retail store. "
                    "Your first message to the customer should be only - Hello, how can I assist you today?"
                    "You reply in crisp and concise, but clear and informative."
                    "Assist customers with product discovery, availability, pricing, order status, returns, and account-related questions."
                    "Ask for necessary order identifiers before sharing sensitive information. "
                    "If a request is unrelated to shopping or orders, politely decline and steer the customer back to supported topics."
                ),
            },
        ]

        context = LLMContext(messages)
        context_aggregator = LLMContextAggregatorPair(context)

        data_dir = Path(__file__).parent / "data"
        db_path_env = os.getenv("ORDERS_DB_PATH")
        db_path = Path(db_path_env) if db_path_env else Path(__file__).parent / "orders.db"

        db_tools = DatabaseTools(db_path=db_path, data_dir=data_dir)
        tool_functions = list(db_tools.tool_functions)
        for tool in tool_functions:
            llm.register_direct_function(tool)

        context.set_tools(ToolsSchema(standard_tools=tool_functions))
        context.set_tool_choice({"type": "auto"})

        rtvi = RTVIProcessor()

        # Pipeline - assembled from reusable components
        pipeline = Pipeline([
            transport.input(),

            rtvi,

            stt,


            context_aggregator.user(),

            llm,

            tts,

            transport.output(),



            context_aggregator.assistant(),

        ])


        task = PipelineTask(
            pipeline,
            params=PipelineParams(
                enable_metrics=True,
                enable_usage_metrics=True,
            ),
            observers=[
                RTVIObserver(rtvi),
            ],
        )

        @transport.event_handler("on_client_connected")
        async def on_client_connected(transport, client):
            logger.info("Client connected")
            # Kick off the conversation
            messages.append({"role": "system", "content": "Say hello and briefly introduce yourself."})
            await task.queue_frames([LLMRunFrame()])

        @transport.event_handler("on_client_disconnected")
        async def on_client_disconnected(transport, client):
            logger.info("Client disconnected")
            await task.cancel()




        runner = PipelineRunner(handle_sigint=False)

        await runner.run(task)


async def bot(runner_args: RunnerArguments):
    """Main bot entry point."""

    transport = None

    match runner_args:
        case SmallWebRTCRunnerArguments():
            webrtc_connection: SmallWebRTCConnection = runner_args.webrtc_connection

            transport = SmallWebRTCTransport(
                webrtc_connection=webrtc_connection,
                params=TransportParams(
                    audio_in_enabled=True,
                    audio_out_enabled=True,
                    vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2)),
                    turn_analyzer=LocalSmartTurnAnalyzerV3(),
                ),
            )
        case _:
            logger.error(f"Unsupported runner arguments type: {type(runner_args)}")
            return

    await run_bot(transport)

def start_health_server():
    async def health(request):
        return web.Response(text='OK')
    
    app = web.Application()
    app.router.add_get('/health', health)
    
    port = int(os.getenv("PORT", 8080))
    print(f"Starting health server on 0.0.0.0:{port}")
    web.run_app(app, host="0.0.0.0", port=port, print=None)


if __name__ == "__main__":

    health_thread = Thread(target=start_health_server, daemon=True)
    health_thread.start()

    # Give health server time to start
    import time
    time.sleep(2)

    # Run Pipecat
    from pipecat.runner.run import main
    main()