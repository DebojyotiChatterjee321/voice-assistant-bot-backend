#
# Copyright (c) 2024–2025, Daily
#
# SPDX-License-Identifier: BSD 2-Clause License
#

"""voice_assistant_bot - Pipecat Voice Agent

This bot uses a cascade pipeline: Speech-to-Text → LLM → Text-to-Speech

Generated by Pipecat CLI

Required AI services:
- Elevenlabs (Speech-to-Text)
- Google_Gemini (LLM)
- Elevenlabs (Text-to-Speech)

Run the bot using::

    uv run bot.py
"""


import os
from pathlib import Path

from aiohttp import ClientSession
from dotenv import load_dotenv
from loguru import logger

from pipecat.audio.turn.smart_turn.local_smart_turn_v3 import LocalSmartTurnAnalyzerV3
from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.frames.frames import LLMRunFrame
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.processors.aggregators.llm_context import LLMContext
from pipecat.processors.aggregators.llm_response_universal import LLMContextAggregatorPair
from pipecat.processors.frameworks.rtvi import RTVIObserver, RTVIProcessor
from pipecat.runner.types import RunnerArguments, SmallWebRTCRunnerArguments
from pipecat.services.elevenlabs.stt import ElevenLabsSTTService
from pipecat.services.elevenlabs.tts import ElevenLabsTTSService
from pipecat.services.google.llm import GoogleLLMService
from pipecat.transports.base_transport import BaseTransport, TransportParams
from pipecat.transports.smallwebrtc.connection import SmallWebRTCConnection
from pipecat.transports.smallwebrtc.transport import SmallWebRTCTransport

from rag import RAGAugmenter, RAGService



load_dotenv(override=True)




async def run_bot(transport: BaseTransport):
    """Main bot logic."""
    logger.info("Starting bot")

    async with ClientSession() as session:
        # Speech-to-Text service
        stt = ElevenLabsSTTService(
            api_key=os.getenv("ELEVENLABS_API_KEY"),
            aiohttp_session=session
        )


        # Text-to-Speech service
        tts = ElevenLabsTTSService(
            api_key=os.getenv("ELEVENLABS_API_KEY"),
            voice_id=os.getenv("ELEVENLABS_VOICE_ID")
        )


        # LLM service
        llm = GoogleLLMService(
            api_key=os.getenv("GOOGLE_API_KEY"),
            model=os.getenv("GOOGLE_MODEL")
        )


        messages = [
            {
                "role": "system",
                "content": (
                    "You are a helpful e-commerce voice assistant for a retail store. "
                    "Your first message to the customer should be only - Hello, how can I assist you today?"
                    "You reply in crisp and concise, but clear and informative."
                    "Assist customers with product discovery, availability, pricing, order status, returns, and account-related questions."
                    "Ask for necessary order identifiers or account details before sharing sensitive information. "
                    "If a request is unrelated to shopping or orders, politely decline and steer the customer back to supported topics."
                ),
            },
        ]

        context = LLMContext(messages)
        context_aggregator = LLMContextAggregatorPair(context)

        data_dir = Path(__file__).parent / "data"
        persist_dir_env = os.getenv("CHROMADB_PERSIST_DIR")
        persist_dir = Path(persist_dir_env) if persist_dir_env else None
        rag_service = RAGService(
            data_dir=data_dir,
            api_key=os.getenv("GOOGLE_API_KEY"),
            embed_model=os.getenv("GOOGLE_EMBED_MODEL", "models/text-embedding-004"),
            persist_dir=persist_dir,
        )

        rag_top_k_env = os.getenv("RAG_TOP_K")
        rag_top_k = 1
        if rag_top_k_env:
            try:
                rag_top_k = max(1, int(rag_top_k_env))
            except ValueError:
                logger.warning("Invalid RAG_TOP_K value '%s'; defaulting to 4", rag_top_k_env)
                rag_top_k = 4

        rag_augmenter = RAGAugmenter(context, rag_service, top_k=rag_top_k)




        rtvi = RTVIProcessor()

        # Pipeline - assembled from reusable components
        pipeline = Pipeline([
            transport.input(),

            rtvi,

            stt,


            context_aggregator.user(),

            rag_augmenter,

            llm,

            tts,

            transport.output(),



            context_aggregator.assistant(),

        ])


        task = PipelineTask(
            pipeline,
            params=PipelineParams(
                enable_metrics=True,
                enable_usage_metrics=True,
            ),
            observers=[
                RTVIObserver(rtvi),
            ],
        )

        @transport.event_handler("on_client_connected")
        async def on_client_connected(transport, client):
            logger.info("Client connected")
            # Kick off the conversation
            messages.append({"role": "system", "content": "Say hello and briefly introduce yourself."})
            await task.queue_frames([LLMRunFrame()])

        @transport.event_handler("on_client_disconnected")
        async def on_client_disconnected(transport, client):
            logger.info("Client disconnected")
            await task.cancel()




        runner = PipelineRunner(handle_sigint=False)

        await runner.run(task)


async def bot(runner_args: RunnerArguments):
    """Main bot entry point."""

    transport = None

    match runner_args:
        case SmallWebRTCRunnerArguments():
            webrtc_connection: SmallWebRTCConnection = runner_args.webrtc_connection

            transport = SmallWebRTCTransport(
                webrtc_connection=webrtc_connection,
                params=TransportParams(
                    audio_in_enabled=True,
                    audio_out_enabled=True,
                    vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2)),
                    turn_analyzer=LocalSmartTurnAnalyzerV3(),
                ),
            )
        case _:
            logger.error(f"Unsupported runner arguments type: {type(runner_args)}")
            return

    await run_bot(transport)


if __name__ == "__main__":
    from pipecat.runner.run import main

    main()